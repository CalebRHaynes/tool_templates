{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Caleb Haynes 6/8/2020 for David Smith & Johanna Jarcho\n",
    "Converts a set of behavioral text files in the AFNI format (seperated txt files) into one 'BIDS' standard file per participant\n",
    "'''\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of all subject level directories to parse over\n",
    "sub_file_list = glob.glob('*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "main function to call in loop, converts a text file to a pandas dataframe with the BIDS format we want with columns for onset, \n",
    "duration and trial_type. We will want to join the dataframes per participant in the loop so we can sort by onset and maintain \n",
    "correct durations and task_types. \n",
    "''' \n",
    "#txt path string, duration int, trial_string\n",
    "def fp_to_pd(txt_path, duration, trial_type):\n",
    "        #I use glob.glob in the loop to find the file. This creates a list object so we use first item in list\n",
    "        #([0]) and use numpy's loadtext module to grab the data inside the txt file. \n",
    "        txt_path = loadtxt(txt_path[0], delimiter=\" \")\n",
    "        #create an initial dictionary to load into pandas with our first column\n",
    "        txt_dict = {'onset': txt_path}\n",
    "        #instantiate pandas df with our dict\n",
    "        df = pd.DataFrame(data = txt_dict)\n",
    "        #add column for duration values\n",
    "        df['duration'] = duration\n",
    "        #add column with the trial_type\n",
    "        df['trial_type'] = trial_type\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oa_onsets/p001\n",
      "['oa_onsets/p001/social/decision/decisionPhase_social_p001.txt']\n",
      "oa_onsets/p002\n",
      "['oa_onsets/p002/social/decision/decisionPhase_social_p002.txt']\n",
      "oa_onsets/p003\n",
      "['oa_onsets/p003/social/decision/decisionPhase_social_p003.txt']\n",
      "oa_onsets/p004\n",
      "['oa_onsets/p004/social/decision/decisionPhase_social_p004.txt']\n",
      "oa_onsets/p005\n",
      "['oa_onsets/p005/social/decision/decisionPhase_social_p005.txt']\n",
      "oa_onsets/p006\n",
      "['oa_onsets/p006/social/decision/decisionPhase_social_p006.txt']\n",
      "ra_onsets/s523\n",
      "['ra_onsets/s523/social/decision/decisionPhase_social_s523.txt']\n",
      "ra_onsets/s571\n",
      "['ra_onsets/s571/social/decision/decisionPhase_social_s571.txt']\n",
      "ra_onsets/s578\n",
      "['ra_onsets/s578/social/decision/decisionPhase_social_s578.txt']\n",
      "ra_onsets/s606\n",
      "['ra_onsets/s606/social/decision/decisionPhase_social_s606.txt']\n",
      "ra_onsets/s707\n",
      "['ra_onsets/s707/social/decision/decisionPhase_social_s707.txt']\n",
      "ra_onsets/s730\n",
      "['ra_onsets/s730/social/decision/decisionPhase_social_s730.txt']\n"
     ]
    }
   ],
   "source": [
    "for i in sub_file_list:\n",
    "    #itertate over each subject, make a path string for each type of file, here decision, positive feedback, and negative \n",
    "    #feedback. \n",
    "    f_social_dec = glob.glob(i + '/social/decision/decisionPhase_social_*')\n",
    "    print(i)\n",
    "    print(f_social_dec)\n",
    "    f_social_fb_pos = glob.glob(i + '/social/feedback/pos*')\n",
    "    f_social_fb_neg = glob.glob(i + '/social/feedback/neg*')\n",
    "    \n",
    "    f_doors_dec = glob.glob(i + '/doors/decision/decisionPhase_doors_*')\n",
    "    f_doors_fb_pos = glob.glob(i + '/doors/feedback/pos*')\n",
    "    f_doors_fb_neg = glob.glob(i + '/doors/feedback/neg*')\n",
    "    \n",
    "    #call function with each file path string, duration, and trial_type\n",
    "    s_df_dec = fp_to_pd(f_social_dec, 3, 'decision')\n",
    "    s_df_fb_pos = fp_to_pd(f_social_fb_pos, 1, 'win')\n",
    "    s_df_fb_neg = fp_to_pd(f_social_fb_neg, 1, 'loss')\n",
    "    \n",
    "    d_df_dec = fp_to_pd(f_doors_dec, 3, 'decision')\n",
    "    d_df_fb_pos = fp_to_pd(f_doors_fb_pos, 1, 'win')\n",
    "    d_df_fb_neg = fp_to_pd(f_doors_fb_neg, 1, 'loss')\n",
    "    \n",
    "    #list of dataframes, merge together\n",
    "    s_df_list = [s_df_dec,s_df_fb_pos,s_df_fb_neg]\n",
    "    s_df_merge = pd.concat(s_df_list)\n",
    "    \n",
    "    d_df_list = [d_df_dec,d_df_fb_pos,d_df_fb_neg]\n",
    "    d_df_merge = pd.concat(d_df_list)\n",
    "    #sort rows by onset values and reset index\n",
    "    df_soc = s_df_merge.sort_values(by=['onset']).reset_index()\n",
    "    df_doors = d_df_merge.sort_values(by=['onset']).reset_index()\n",
    "    \n",
    "    soc_filename = f'sub-{i[-3:]}_face-A.tsv'\n",
    "    door_filename = f'sub-{i[-3:]}_image-A.tsv'\n",
    "    \n",
    "    df_soc.to_csv(soc_filename, columns = ['onset', 'duration', 'trial_type'],index =False, sep ='\\t')\n",
    "    df_doors.to_csv(door_filename, columns = ['onset', 'duration', 'trial_type'],index =False, sep ='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afni_to_BIDS.ipynb   sub-004_face-A.tsv   sub-571_image-A.tsv\r\n",
      "oa_onsets\t     sub-004_image-A.tsv  sub-578_face-A.tsv\r\n",
      "ra_onsets\t     sub-005_face-A.tsv   sub-578_image-A.tsv\r\n",
      "sub-001_face-A.tsv   sub-005_image-A.tsv  sub-606_face-A.tsv\r\n",
      "sub-001_image-A.tsv  sub-006_face-A.tsv   sub-606_image-A.tsv\r\n",
      "sub-002_face-A.tsv   sub-006_image-A.tsv  sub-707_face-A.tsv\r\n",
      "sub-002_image-A.tsv  sub-523_face-A.tsv   sub-707_image-A.tsv\r\n",
      "sub-003_face-A.tsv   sub-523_image-A.tsv  sub-730_face-A.tsv\r\n",
      "sub-003_image-A.tsv  sub-571_face-A.tsv   sub-730_image-A.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
